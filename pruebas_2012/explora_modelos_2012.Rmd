---
title: "Simulaciones 2012"
output: html_document
---

```{r options, echo = FALSE, message=FALSE, error=TRUE, warning=FALSE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE, 
    cache=TRUE
  )
comma <- function(x) format(x, digits = 2, big.mark = ",")
options(digits=3)

library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
```

En este documento pretendemos recrear el proceso del COTECORA 2012 para ello 
usamos la lista completa de resultado de las elecciones presidenciales de 2012
y seguimos los siguientes pasos: 1) definimos lo estratos, 2) seleccionamos una
muestra, 3) estimamos siguiendo la documentación del método clásico y del 
bayesiano. 

## Selección de muestra

### Descripción del proceso de selección

El diseño muestral corresponde a un muestreo estratificado simple de casillas 
con 483 estratos. El tamaño de muestra es de 7,597 casillas. Con este número de 
casillas y número de estratos se espera obtener precisiones mayores a medio 
punto porcentual, 0.5%, con al menos 95% de confianza.

La estratificación se construyó al considerar el cruce de los trescientos 
distritos electorales con el tipo de sección de pertenencia de las casillas, 
urbano y no urbano respetando un mínimo de tres casillas en muestra por estrato. 
La distribución de la muestra a los estratos se realizó en forma proporcional al 
número de casillas en el estrato; la muestra inicial fué suplementada con una 
sobremuestra de 97 casillas en total, 58 en Sonora, 33 en Baja California y 6 en 
Baja California Sur por consideraciones de huso horario.

El marco muestral utilizado fue el listado nominal proporcionado por la 
Dirección Ejecutiva de Organización Electoral el día 27 de junio del 2012, 
conteniendo un universo de 143,456 casillas electorales. Este universo incluye a 
las 305 actas de escrutinio y cómputo del voto de mexicanos residentes en el 
extranjero, las cuales, para fines del conteo rápido, se consideran como 
casillas electorales.


### Simulación de muestra

Usaremos los datos de cómputos distritales 2012 descargable en el [portal del INE](http://portalanterior.ine.mx/archivos3/portal/historico/contenido/Procesos_Electorales_Acervo_Electronico/). La descripción de los datos se encuentra en el archivo [dd_COMPUTOS2012.html](datos/datos_computos_2012_09072012_2015/dd_COMPUTOS2012.hmtl)

Las variables en la base son:

```{r leer datos, message=FALSE}
library(tidyverse)
library(stringr)

# cómputos presidente
computos_p <- read_delim("datos/datos_computos_2012_09072012_2015/datos_computos_casillas_presidente.txt",
    "|", escape_double = FALSE, trim_ws = TRUE)

glimpse(computos_p)
```

Creamos los estratos.

```{r}
# añadimos variable estrato
# distrito electoral se construye con ESTADO y D_DISTRITO, CASILLA indica urbana (1)
# y no urbana (2)
computos_estrato <- computos_p %>% 
    mutate(
        DISTRITO = str_c(ID_ESTADO, D_DISTRITO, sep = "-"), 
        ESTRATO = str_c(DISTRITO, CASILLA, sep = "-")
        )
```

Si construímos los distritos electorales como ESTADO-D_DISTRITO obtenemos los 
`r n_distinct(computos_estrato$DISTRITO)` distritos electorales que se describen 
en la documentación. Si después construimos los estratos como 
DISTRITO-CASILLA (urbana, no-urbana) obtenemos 
`r n_distinct(computos_estrato$ESTRATO)` que son más de los 483 estratos 
mencionados en la descripción de la muestra, concluimos que se colapsaron los 
estratos con menos de 55 casillas asignándolos al estrato del mismo distrito 
(así llegamos a 483 estratos). 

En las siguientes lineas determinamos los estratos colapsados y calculamos el 
tamaño de muestra en cada uno utilizando asignación proporcional.

```{r}
estrato_colapso <- computos_estrato %>% 
    group_by(ID_ESTADO, D_DISTRITO, CASILLA, ESTRATO) %>% 
    summarise(n_casillas = n()) %>% 
    ungroup() %>% 
    mutate(
        ESTRATO_aux = str_c(ID_ESTADO, D_DISTRITO, (CASILLA %% 2 + 1), sep = "-"),
        ESTRATO_colapsado = case_when(
            n_casillas > 54 ~ ESTRATO, 
            TRUE ~ ESTRATO_aux), 
        ESTRATO_num = as.integer(parse_factor(ESTRATO_colapsado, levels = ESTRATO_colapsado))
        ) %>% 
    select(ID_ESTADO, D_DISTRITO, CASILLA, ESTRATO = ESTRATO_num)

# n_distinct(estrato_colapso$ESTRATO)    

# tamaño de muestra proporcional al número de casillas en el estrato
n <- 7597
computos <- computos_p %>% 
    left_join(estrato_colapso, by = c("ID_ESTADO", "D_DISTRITO", "CASILLA"))

# tomamos muestra
tamano_muestra <- computos %>% 
    group_by(ID_ESTADO, ESTRATO) %>% 
    summarise(n_casillas = n()) %>% 
    ungroup() %>% 
    mutate(n_muestra = round(n_casillas / sum(n_casillas) * n))

tamano_muestra %>% 
    group_by(ID_ESTADO) %>% 
    summarise(sum(n_muestra))
```

Por efectos de redondeo la muestra final tiene `r sum(tamano_muestra$n_muestra)`
casillas (en lugar del objetivo de 7,597), con un tamaño de muestra mínimo de 
`r min(tamano_muestra$n_muestra)` casillas por estrato.

Seleccionamos las casillas en la muestra ejemplo.

```{r}
set.seed(2638762)
muestra_sim <- computos %>% 
    left_join(tamano_muestra, by = "ESTRATO") %>% 
    split(.$ESTRATO) %>% 
    map_df(~sample_n(., size = first(.$n_muestra)))

muestra_sim
```

Usaremos esta muestra para estimar las proporción de votos en favor de cada 
partido usando el método clásico y el método bayesiano.

## Modelo Clásico

Se utiliza un estimador de razón, el estimador de la proporción de votos para el 
$j$-ésimo candidato es

$$\hat{p_j}=\frac{\hat{Y_j}}{\hat{X}}=\frac{\sum_h \hat{Y_{jh}}}{\sum_h \hat{X_{h}}}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{jhi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
Estimemos la proporción a favor del PRI usando la muestra simulada (podríamos
usar la muestra final de COTECORA pero por facilidad usamos la simulación).

```{r}
p_pri <- muestra_sim %>% 
    mutate(
        Y = n_casillas / n_muestra * (PRI + PVEM + PRI_PVEM), 
        X = n_casillas / n_muestra * TOTAL_VOTOS, 
        id = 1:nrow(muestra_sim)
        ) %>% 
    select(id, ESTRATO, n_muestra, X, Y)
est_p_pri <- 100 * sum(p_pri$Y) / sum(p_pri$X)
```

La proporción estimada es `r comma(est_p_pri)`. 

**Duda.** De acuerdo a la [documentación del modelo clásico](http://portalanterior.ine.mx/documentos/proceso_2011-2012/alterna/docs/cotecora-Met-Clasico.pdf) el denominador del estimador de
razón $X_{hi}$ es el número de votos totales emitidos en la casilla $i$ del 
estrato $h$, sin embargo, el paper de *Quick counts in the Mexican...*
menciona que el denominador sería los votos válidos.

Usamos bootstrap para calcular el error estándar.

```{r pri_boot, cache = TRUE}
# hacemos el remuestreo dentro de cada estrato
# código lento, usar split y sample_frac es muy lento
# boot_pri <- function(){
#     p_pri_b <- p_pri %>% 
#         split(.$ESTRATO) %>% 
#         map_df(~sample_frac(., size = 1, replace = TRUE))
#     round(100 * sum(p_pri_b$Y) / sum(p_pri_b$X), 2)
# }

# 6 veces más rápido que el anterior pero aún lento
boot_pri <- function(){
    p_pri_ids <- p_pri %>% 
        split(.$ESTRATO) %>% 
        map(~sample(.$id, size = first(.$n_muestra), replace = TRUE)) %>% 
        flatten_dbl()
    p_pri_b <- p_pri[p_pri_ids, ]
    round(100 * sum(p_pri_b$Y) / sum(p_pri_b$X), 2)
}

p_pri_boot <- rerun(1000, boot_pri()) %>% flatten_dbl()
e_est <- sd(p_pri_boot)
```


```{r boot_profiling, include = FALSE}
# código para perfilar la función y hacerla más rápido
library(profvis)

profvis({
boot_pri <- function(){
    p_pri_ids <- p_pri %>% 
        split(.$ESTRATO) %>% 
        map(~sample(.$id, size = first(.$n_muestra), replace = TRUE)) %>% 
        flatten_dbl()
    p_pri_b <- p_pri[p_pri_ids, ]
    round(100 * sum(p_pri_b$Y) / sum(p_pri_b$X), 2)
}


p_pri_boot <- rerun(10, boot_pri()) %>% flatten_dbl()
})
```

La estimación del error estándar usando bootstrap es `r comma(e_est)`, y el 
intervalo quedaría (`r stringr::str_c(round(est_p_pri - 2 * e_est, 2), round(est_p_pri + 2 * e_est, 2), sep = ",")`), 
mientras que el intervalo reportado en el COTECORA 2012 fue (37.93,38.55).

```{r}
# proporción en la población
prop_real <- 100 * sum(computos_p$PRI + computos_p$PVEM + computos_p$PRI_PVEM) /
    sum(computos_p$TOTAL_VOTOS)
```

La proporción en la población es `r round(prop_real, 2)` y    podemos usar 
simualción para calcular el verdadero error estándar.

```{r error_real, cache=TRUE}
# creamos una tabla con la información del PRI
computos_pri <- computos %>% 
    left_join(tamano_muestra, by = "ESTRATO") %>% 
    mutate(
        Y = n_casillas / n_muestra * (PRI + PVEM + PRI_PVEM), 
        X = n_casillas / n_muestra * TOTAL_VOTOS, 
        id = 1:nrow(computos)
        ) %>% 
    select(id, ESTRATO, n_muestra, X, Y)

# la función selecciona la muestra y estima la prop. de  votos PRI
est_pri <- function(){
    p_pri_ids <- computos_pri %>% 
        split(.$ESTRATO) %>% 
        map(~sample(.$id, size = first(.$n_muestra))) %>% 
        flatten_dbl()
    p_pri_m <- computos_pri[p_pri_ids, ]
    100 * sum(p_pri_m$Y) / sum(p_pri_m$X)
}
# estimaciones de la proporción con distintas muestras
p_pri_est <- rerun(1000, est_pri()) %>% flatten_dbl()
# error estándar de las estimaciones
e_est_real <- sd(p_pri_est)
```

El error estándar real es aproximadamente `r comma(e_est_real)`, cercano a la
estimación bootstrap.

El estimador de razón es sesgado, es posible hacer correcciones o quizá sería 
conveniente usar el error cuadrático medio en lugar del error estándar. Dada la 
correlación entre $X$ y $Y$ suponemos que el sesgo es chico. Podemos usar las 
simulaciones de arriba para aproximar el sesgo.

```{r}
sesgo <- mean(p_pri_est) - prop_real
```
Obtenemos que el sesgo es `r comma(sesgo)` y el sesgo al cuadrado es
`r comma(sesgo ^ 2)`, por lo que no vale la pena hacer correcciones y reportar
el error estándar es suficiente.

#### Notas modelo clásico

* ¿Estamos asumiendo un diseño de muestreo con reemplazo?

* ¿No hay corrección por población finita? Para algunos estratos parece no ser
despreciable.

* ¿Vale la pena corregir el sesgo?

### Muestra definitiva COTECORA 2012

Datos obtenidos del [portal del INE](http://portalanterior.ine.mx/archivos3/portal/historico/contenido/Procesos_Electorales_Acervo_Electronico/). Replicamos el ejercicio de arriba con la muestra que se usó en 
COTECORA 2012.

** aún no lo hago porque no pude pegar las bases**

```{r muestra_cotecora, eval=FALSE}
muestra <- read_delim("datos/cotecora-MuestraDefinitiva/Muestra Definitiva/muestra2.txt", 
    "|", escape_double = FALSE, trim_ws = TRUE)

# al seleccionar las casillas en la muestra COTECORA pierdo 31, de las cuales
# 29 son de TIPO_CASILLA = V
muestra_computos <- computos %>% 
    select(-ESTRATO) %>% 
    rename(ID_DISTRITO = D_DISTRITO) %>% 
    semi_join(muestra, by = c("ID_ESTADO", "SECCION", "TIPO_CASILLA", 
        "ID_CASILLA", "EXT_CONTIGUA", "LISTA_NOMINAL"))

muestra %>% 
    anti_join(select(computos, -ESTRATO),by = c("ID_ESTADO", "SECCION", "TIPO_CASILLA", 
        "ID_CASILLA", "EXT_CONTIGUA", "LISTA_NOMINAL"))

```

## Modelo Bayesiano

El siguiente código se hace con base en la [documentación del modelo Bayesiano](http://portalanterior.ine.mx/documentos/proceso_2011-2012/alterna/docs/cotecora-Met-Bayesiano.pdf) 

Supuestos

* Las iniciales son no-informativas e iguales para todos los candidatos. Por 
imparcialidad de INE.

* $X_{ij}^k$ es independiente de $X_{ij'}^k$ con $j \ne j'$, esto es, en un 
mismo estrato el número de votos del $j$ésimo candidato es independiente del 
número de votos que reciben los demás. De acuerdo con los autores modelos más 
complejos mostraron que la dependencia era muy débil y podía ignorarse.


### Verosimilitud
$$X_{ij}^k\big|\theta_{ij},\tau_{ij}\sim N\bigg(n_i^k\theta_{ij}, \frac{\tau_{ij}}{n_i^k}\bigg)$$

para $k=1,...,c_i$, $i = 1,...,N$, $j=1,...,J$

### Posterior
$$p(\theta_{ij}, \tau_{ij}|X_{ij}) \sim N\bigg(\theta_{ij} \bigg| \frac{\sum_{k=1}^{c_i}x_{ij}^k}{\sum_{k=1}^{c_i}n_{i}^k}, \tau_{ij}\sum_{k=1}^{c_i}n_i^k\bigg)I(0<\theta_{ij}<1)\times Ga\bigg(\tau_{ij}\bigg|\frac{c_i-1}{2}, \frac{1}{2}\bigg[\sum_{k=1}^{c_i}\frac{(x_{ij}^k)^2}{n_i^k}-\frac{\big(\sum_{k=1}^{c_i}x_{ij}^k\big)^2}{\sum_{k=1}^{c_i}n_i^k}\bigg]\bigg)$$
para $i = 1,...,N$, $j=1,...,J$.

#### Notación

* $X_{ij}$ número de personas que favorecen al candidato $j$ en el estrato $i$.

* $X_{ij}^k$ número de personas que favorecen al candidato $j$ en la casilla $k$ 
del estrato $i$.

* $n_i^k$ tamaño de la lista nominal en la $k$-ésima casilla del $i$-ésimo 
estrato.

* $\tau_{ij}/n_i^{k}$ es la precisión para cada candidato, sin relación con
$\theta_{ij}$.

* $\theta_{ij}$ es la proporción de las personas en la lista nominal del estrato
$i$ que favorecen al $j$-ésimo partido.

* $c_i$ número de casillas del $i$-ésimo estrato en la muestra.

Creamos una función para simular de la posterior y así hacer inferencia de las
verdaderas proporciones.

```{r}
# usar lista nominal produce errores por ceros en casillas especiales quizá 
# habría que eliminarlas desde el inicio pero en la muestra COTECORA 2012
# si aparecen

datos_bayes <- muestra_sim %>% 
    filter(LISTA_NOMINAL > 0) %>% 
    mutate(
        # BOLETAS_INUTILIZADAS = ifelse(is.na(BOLETAS_INUTILIZADAS), 0, BOLETAS_INUTILIZADAS),
        x_pri = PRI + PVEM + PRI_PVEM, 
        x_pan = PAN,
        x_prd = PRD + PT + MC + PT_MC + PRD_PT_MC + PRD_PT + PRD_MC,
        x_alianza = PANAL, 
        x_nulos = NUM_VOTOS_NULOS, # + BOLETAS_INUTILIZADAS,
        x_no_reg = NUM_VOTOS_CAN_NREG, 
        x_otros = x_alianza + x_nulos + x_no_reg) %>% 
    select(estrato = ESTRATO, n = LISTA_NOMINAL, x_pri, c = n_muestra, x_pri, 
        x_pan, x_prd, x_alianza, x_nulos, x_no_reg, x_otros)
    # select(estrato = ESTRATO, n = TOTAL_VOTOS, x_pri, c = n_muestra)

datos_bayes

# sims_posterior <- function(x_j, n, n_sims = 200){
#     theta_sims <- rep(NA, n_sims)
#     tau_sims <- rep(NA, n_sims)
#     # parámetros Gamma
#     a_gamma <- (length(n) - 1) / 2
#     b_gamma <- 1/ 2 * (sum(x_j ^ 2 / n) - sum(x_j) ^ 2 / sum(n))
#     tau <- rgamma(1, shape = a_gamma, rate = b_gamma)
#     # parámetros normal
#     media_normal <- sum(x_j) / sum(n)
#     desv_normal <- sqrt(1 / (tau * sum(n)))
#     theta <- rnorm(1, media_normal, desv_normal)
#     # caminata
#     m <- 1
#     while(m <= n_sims){
#         if(theta > 0 & theta < 1){
#             theta_sims[m] <- theta
#             tau_sims[m] <- tau
#             m <- m + 1
#         }
#         tau <- rgamma(1, a_gamma, b_gamma)
#         desv_normal <- sqrt(1 / (tau * sum(n)))
#         theta <- rnorm(1, media_normal, desv_normal)
#     }
#     return(list(theta_mean = mean(theta_sims), 
#         sims_list = list(theta = theta_sims, tau = tau_sims), 
#         n_i = sum(n)))
# }

sims_posterior <- function(x_j, n, n_sims = 200){
  theta_sims <- NULL
  tau_sims <- NULL
  while(length(theta_sims) < n_sims){
    # parametros Gamma
    a_gamma <- (length(n) - 1) / 2
    b_gamma <- 1/ 2 * (sum(x_j ^ 2 / n) - sum(x_j) ^ 2 / sum(n))
    tau <- rgamma(n_sims, shape = a_gamma, rate = b_gamma) # aqui igual y me conviene simular mas, habria que ver que es lo mas eficiente dependiendo de la probabilidad de que theta este en el (0,1)
    # parametros normal
    media_normal <- sum(x_j) / sum(n)
    desv_normal <- sapply(tau, function(tau_i){sqrt(1 / (tau_i * sum(n)))})
    theta <- sapply(desv_normal, function(desv_i){rnorm(1, media_normal, desv_i)})
    indices <- which(theta > 0 & theta < 1)
    theta_sims <- c(theta_sims, theta[indices])
    tau_sims <- c(tau_sims, tau[indices])
  }
  return(list(theta_mean = mean(theta_sims[1:n_sims]), 
              sims_list = list(theta = theta_sims[1:n_sims], tau = tau_sims[1:n_sims]), 
              n_i = sum(n)))
  }



# calculamos la media posterior para cada estrato
thetas_aux <- datos_bayes %>% 
    group_by(estrato) %>% 
    summarise(
        n_i = sum(n),
        theta_pri = sims_posterior(x_pri, n)$theta_mean, 
        theta_pan = sims_posterior(x_pan, n)$theta_mean, 
        theta_prd = sims_posterior(x_prd, n)$theta_mean, 
        theta_otros = sims_posterior(x_otros, n)$theta_mean
        # theta_alianza_w = sims_posterior(x_alianza, n), 
        # theta_nulos_w = sims_posterior(x_nulos, n),
        # theta_no_reg_w = sims_posterior(x_no_reg, n)
        )

# tenemos que calcular para cada generación de theta_j y no con las medias
# calculamos la media posterior de theta_j y las lambda_j
# thetas_aux %>% 
#     gather(parametro, media_post, contains("theta")) %>% 
#     group_by(parametro) %>% 
#     summarise(theta = sum(n_i * media_post / sum(n_i))) %>% 
#     ungroup() %>% 
#     mutate(lambda = comma(100 * theta / sum(theta))) %>% 
#     select(-theta)

```

Calculamos $\lambda_j$ y graficamos las simulaciones de la posterior.

```{r calcular_lambdas, fig.width = 6.5, fig.height=2.8}
thetas_aux <- datos_bayes  %>% 
    gather(partido, conteos, contains("x_")) %>% 
    filter(!(partido %in% c("x_alianza", "x_nulos", "x_no_reg"))) %>% 
    group_by(estrato, partido) %>% 
    do(theta_sims = sims_posterior(.$conteos, .$n)) %>% 
    ungroup() 

# combina las simulaciones de distintos estratos para formar las simulaciones de
# theta_j a nivel partido
sim_theta_j <- function(datos){
    # datos: conjunto de datos con las simulaciones de theta_ji
    thetas_mat <- map(datos$theta_sims, ~.$sims_list$theta) %>% 
        do.call(cbind, .)
    n_i <- map(datos$theta_sims, ~.$n_i) %>% 
        flatten_dbl()
    thetas_j <- thetas_mat %*% n_i / sum(n_i)
    return(thetas_j)
}

thetas_j_sims <- thetas_aux %>% 
    group_by(partido) %>% 
    do(theta_j = sim_theta_j(.))

lambda_j_sims <- thetas_j_sims$theta_j %>% 
    do.call(cbind, .) %>% 
    apply(1, function(x) x / sum(x)) %>% 
    t(.)

colnames(lambda_j_sims) <- str_replace(thetas_j_sims$partido, "x_", "")

estimaciones <- data.frame(n_sim = 1:nrow(lambda_j_sims), lambda_j_sims) %>% 
    gather(partido, sim, -n_sim) %>% 
    filter(partido != "otros")

medias_post <- estimaciones %>% 
    group_by(partido) %>% 
    summarise(
        mean_sim = mean(sim) * 100, 
        median_sim = median(sim) * 100, 
        sd_sim = sd(sim) * 100
        )

ggplot(estimaciones, aes(x = sim)) +
    geom_histogram(binwidth = 0.0005, alpha = 0.7) +
    facet_wrap(~partido, scales = "free_x") +
    geom_vline(data = medias_post, aes(xintercept = mean_sim / 100), color = "red")
    
```

Las medias posteriores están indicadas por la linea vertical, y quedarían:

```{r}
library(knitr)
library(kableExtra)
medias_post %>% 
    mutate_if(is.double, round, digits = 2) %>% 
    kable()
```


### Dudas
Cómo se trata la lista nominal en las casillas especiales?

Las boletas inutilizadas entran en votos nulos?

Cuando $\theta_{ji}$ es muy chica (por ejemplo candidatos no registrados) se 
rechazan muchas simulaciones y se vuelve muy lento.

### Glosario

**Circunscripciones electorales:** Área geográfica integrada por un grupo de 
entidades federativas, que sirve de base para la elección de los 200 diputados 
electos por el principio de representación proporcional. Hay 5 circunscripciones.

**Tipo de casilla** 
    + Básica(B): Se instalan en secciones que tienen un número no mayor a 750 electores.
    
    + Contigua(C): Cuando el número de electores de la sección es superior a 750, éstas se instalan.
    
    + Extraordinaria(E): Atienden a residentes de una sección, que por condiciones de vías de comunicación o socio culturales, tengan difícil acceso
    
    + Especial(S): Se instalan para que los electores fuera de la sección correspondiente a su domicilio puedan votar. 
    
    + Extranjero(M,V): Casilla en el extranjero, en la base nacional codificado como M, en 
    la muestra codificado como V.
    
### Ideas

* Modelar la dependencia de las $\theta_{ij}$ es decir $\sum_j \theta_{ij}=1$.

* Agregar estructura jerárquica a modelo, es decir, estimar $\theta_{ij}$ en un 
solo modelo.

* Agregar covariables a nivel casilla, ayudaría a mejorar inferencias cuando hay 
pocos datos. Ideas de [Mister P](http://andrewgelman.com/2013/10/09/mister-p-whats-its-secret-sauce/). (multiple regression post-stratification). Complicación puede ser tiempo de 
estimación pues habría que simular la votación para cada casilla (~140,000).